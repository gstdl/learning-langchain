{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_api_key = os.environ[\"OPENAI_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " without drinking\n",
      "\n",
      "Yes, absolutely! There are many ways to have fun without alcohol. Here are some ideas:\n",
      "\n",
      "1. Try new activities: Instead of going to a bar or club, try out a new hobby or activity. This could be anything from painting, hiking, or joining a sports team. You might discover a new passion and have fun while doing it.\n",
      "\n",
      "2. Spend time with friends: Plan a fun day out with friends that doesn't revolve around drinking. You could go to a theme park, have a picnic, or go to a concert. Spending time with loved ones can be enjoyable without alcohol.\n",
      "\n",
      "3. Attend events: Look for local events such as festivals, concerts, or art shows. These events can be a great way to have fun and meet new people without drinking.\n",
      "\n",
      "4. Have a game night: Invite friends over for a game night. You can play board games, card games, or even video games. This is a great way to have fun and connect with others without alcohol.\n",
      "\n",
      "5. Learn a new skill: Take a class or workshop to learn a new skill. This could be anything from cooking to dancing. Not only will you have fun, but you will also gain a new skill.\n",
      "\n",
      "6. Volunteer: Volunteering can be\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "question = 'Can you still have fun'\n",
    "\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting and chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='You are a Biology Professor, answer the question. {question}')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"You are a Biology Professor, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The pancreas is a vital organ in the human body that plays an important role in the digestive and endocrine systems. Its main function is to produce and release digestive enzymes and hormones that help with the digestion and absorption of nutrients from food.\n",
      "\n",
      "The pancreas produces and secretes digestive enzymes such as amylase, lipase, and proteases that help break down carbohydrates, fats, and proteins respectively. These enzymes are released into the small intestine where they aid in the breakdown of food particles into smaller molecules that can be absorbed by the body.\n",
      "\n",
      "In addition to producing digestive enzymes, the pancreas also secretes hormones such as insulin and glucagon that regulate blood sugar levels. Insulin helps to lower blood sugar levels by promoting the uptake of glucose by cells, while glucagon increases blood sugar levels by promoting the release of glucose from the liver.\n",
      "\n",
      "Overall, the pancreas plays a crucial role in maintaining the body's metabolism and ensuring proper digestion and absorption of nutrients. Dysfunction of the pancreas can lead to various health issues, such as diabetes and digestive disorders. \n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "template = \"You are a Biology Professor, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "result = chain.invoke({\"question\": \"What's the function of Pancreas?\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System: Dari makhluk terindah kita menginginkan peningkatan,\n",
      "Sehingga mawar kecantikan tidak pernah mati,\n",
      "Tapi seperti yang lebih tua harus mati oleh waktu,\n",
      "Anak lembutnya bisa membawa ingatannya:\n",
      "Tapi engkau terikat pada mata indahmu sendiri,\n",
      "Mengisi nyala cahaya dengan bahan bakar yang substansial,\n",
      "Membuat kelaparan di tempat kekayaan berlimpah,\n",
      "Dirimu musuhmu, terlalu kejam pada dirimu yang manis:\n",
      "Kamu yang sekarang adalah perhiasan baru dunia,\n",
      "Dan satu-satunya pembawa pesan musim semi yang mencolok,\n",
      "Dalam kuncupmu sendiri, kamu mengubur kepuasanmu,\n",
      "Dan membuat pemborosan dengan menjadi kikir:\n",
      "Sayangilah dunia, atau jadilah pemakan yang rakus,\n",
      "Memakan hak dunia, oleh kematian dan dirimu.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that translates the {input_language} to {output_language}\"),\n",
    "    (\"user\", \"Translate the following passage: {passage}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"input_language\": \"English\", \n",
    "    \"output_language\": \"Bahasa Indonesia\", \n",
    "    \"passage\": \"\"\"From fairest creatures we desire increase,\n",
    "That thereby beauty's rose might never die,\n",
    "But as the riper should by time decease,\n",
    "His tender heir might bear his memory:\n",
    "But thou contracted to thine own bright eyes,\n",
    "Feed'st thy light's flame with self-substantial fuel,\n",
    "Making a famine where abundance lies,\n",
    "Thy self thy foe, to thy sweet self too cruel:\n",
    "Thou that art now the world's fresh ornament,\n",
    "And only herald to the gaudy spring,\n",
    "Within thine own bud buriest thy content,\n",
    "And tender churl mak'st waste in niggarding:\n",
    "Pity the world, or else this glutton be,\n",
    "To eat the world's due, by the grave and thee.\"\"\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Describe a language model in one sentence\n",
      "A: \n",
      "\n",
      "A language model is a statistical model that assigns probabilities to sequences of words in order to predict and generate natural language text.\n",
      "Q: Describe it again using less words\n",
      "A: \n",
      "\n",
      "Explain more succinctly\n",
      "Q: Describe it again fewer words but at least one word\n",
      "A: \n",
      "Shorten\n",
      "\n",
      "Q: What did I first ask you? I forgot.\n",
      "A: \n",
      "\n",
      "I believe you first asked me \"What did I first ask you?\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "for question in [\n",
    "    \"Describe a language model in one sentence\",\n",
    "    \"Describe it again using less words\",\n",
    "    \"Describe it again fewer words but at least one word\",\n",
    "    \"What did I first ask you? I forgot.\",\n",
    "]:\n",
    "    output = llm.invoke(question)\n",
    "    print(\"Q:\", question)\n",
    "    print(\"A:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Describe a language model in one sentence\n",
      "A: A language model is a statistical model that predicts the likelihood of a sequence of words occurring in a given context.\n",
      "Q: Describe it again using less words\n",
      "A: Sure, I can help with that.\n",
      "Q: Describe it again fewer words but at least one word\n",
      "A: Concise description, please.\n",
      "Q: What did I first ask you? I forgot.\n",
      "A: You first asked me, \"What did I first ask you? I forgot.\"\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "for question in [\n",
    "    \"Describe a language model in one sentence\",\n",
    "    \"Describe it again using less words\",\n",
    "    \"Describe it again fewer words but at least one word\",\n",
    "    \"What did I first ask you? I forgot.\",\n",
    "]:\n",
    "    inputs = {\"input\": question}\n",
    "    output = chain.invoke(inputs)\n",
    "    print(\"Q:\", question)\n",
    "    print(\"A:\", output.content)\n",
    "    memory.save_context(inputs, {\"output\": output.content})\n",
    "\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "A black hole is a region in space where the gravitational pull is so strong that nothing, not even light, can escape from it. This happens when a massive star collapses in on itself, creating a singularity with an extremely high density. The boundary surrounding a black hole is called the event horizon. Black holes have been theorized and observed in our universe, and they play a significant role in understanding the laws of physics, particularly in the study of gravity and spacetime.\n",
      "Using MATH\n",
      "A path integral is a concept in mathematics and physics that involves calculating the integral of a function along a specific path or trajectory. In physics, it is commonly used in quantum mechanics to calculate the probability amplitude for a particle to move from one point to another. In mathematics, it can be used to calculate the total change in a function along a specific path. The path integral is often used in fields such as calculus, differential equations, and quantum field theory.\n",
      "Using MATH\n",
      "To find x, we can start by solving the equation 2x + 3 = 32.\n",
      "\n",
      "Subtract 3 from both sides:\n",
      "2x = 29\n",
      "\n",
      "Divide by 2 on both sides:\n",
      "x = 29/2\n",
      "\n",
      "Therefore, x = 14.5.\n",
      "Using PHYSICS\n",
      "Barack Obama is a former President of the United States. He served as the 44th President from 2009 to 2017.\n"
     ]
    }
   ],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"What's a black hole\"))\n",
    "print(chain.invoke(\"What's a path integral\"))\n",
    "print(chain.invoke(\"Find x, 2x + 3 = 32\"))\n",
    "print(chain.invoke(\"Who's Barack Obama?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/langchain-demo/lib/python3.12/site-packages/langchain_community/vectorstores/pgvector.py:289: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n",
      "Created a chunk of size 177, which is longer than the specified 150\n",
      "Created a chunk of size 229, which is longer than the specified 150\n",
      "Created a chunk of size 233, which is longer than the specified 150\n",
      "Created a chunk of size 185, which is longer than the specified 150\n",
      "Created a chunk of size 203, which is longer than the specified 150\n",
      "Created a chunk of size 299, which is longer than the specified 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "page_content='Q: What are the hours of operation for Bella Vista?\\nA: Bella Vista is open from 11 a.m. to 11 p.m. from Monday to Saturday. On Sundays, we welcome guests from 12 p.m. to 10 p.m.' metadata={'source': './bella-vista.txt'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_added': 1, 'num_updated': 0, 'num_skipped': 6, 'num_deleted': 1}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain.schema import Document\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://admin:admin@127.0.0.1:5455/vectordb\"\n",
    "COLLECTION_NAME = \"vectordb\"\n",
    "\n",
    "\n",
    "vectorstore = PGVector.from_documents(\n",
    "    [],\n",
    "    embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING\n",
    ")\n",
    "\n",
    "loader = TextLoader(\"./bella-vista.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=150, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(len(docs))\n",
    "print(docs[0])\n",
    "\n",
    "\n",
    "# Update namespace to reflect PGVector\n",
    "namespace = f\"pgvector/{COLLECTION_NAME}\"\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace, db_url=CONNECTION_STRING\n",
    ")\n",
    "\n",
    "# Create schema for the record manager\n",
    "record_manager.create_schema()\n",
    "\n",
    "index(\n",
    "    docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    # cleanup=None, # handles some deduplication\n",
    "    # cleanup=\"incremental\", # does not handle deduplication\n",
    "    cleanup=\"full\", # deletes everything then indexes the new documents\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Q: What are the hours of operation for Bella Vista?\\nA: Bella Vista is open from 11 a.m. to 11 p.m. from Monday to Saturday. On Sundays, we welcome guests from 12 p.m. to 10 p.m.', metadata={'source': './bella-vista.txt'}),\n",
       "  0.19554248556236586),\n",
       " (Document(page_content='Q: Do I need a reservation for Bella Vista?\\nA: While walk-ins are always welcome, we recommend making a reservation, especially during weekends and holidays, to ensure a seamless dining experience.', metadata={'source': './bella-vista.txt'}),\n",
       "  0.20729634956837273),\n",
       " (Document(page_content='Q: Do you offer vegetarian or vegan options at Bella Vista?\\nA: Absolutely! Bella Vista boasts a diverse menu that includes a variety of vegetarian and vegan dishes. Our chefs are also happy to customize dishes based on dietary needs.', metadata={'source': './bella-vista.txt'}),\n",
       "  0.23737657584028382),\n",
       " (Document(page_content='Q: Can I book private events at Bella Vista?\\nA: Certainly! Bella Vista has a private dining area perfect for events, parties, or corporate gatherings. We also offer catering services for off-site events.', metadata={'source': './bella-vista.txt'}),\n",
       "  0.2457998585438067)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(\"when does the restaurant open?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Q: Do I need a reservation for Bella Vista?\\nA: While walk-ins are always welcome, we recommend making a reservation, especially during weekends and holidays, to ensure a seamless dining experience.', metadata={'source': './bella-vista.txt'}),\n",
       " Document(page_content='Q: Can I book private events at Bella Vista?\\nA: Certainly! Bella Vista has a private dining area perfect for events, parties, or corporate gatherings. We also offer catering services for off-site events.', metadata={'source': './bella-vista.txt'}),\n",
       " Document(page_content=\"Q: Is Bella Vista family-friendly?\\nA: Yes, Bella Vista is a family-friendly establishment. We have a dedicated kids' menu and offer high chairs and booster seats for our younger guests.\", metadata={'source': './bella-vista.txt'}),\n",
       " Document(page_content=\"Q: What's the ambiance like at Bella Vista?\\nA: Bella Vista boasts a cozy and elegant setting, with ambient lighting, comfortable seating, and a stunning view of the city skyline. Whether you're looking for a romantic dinner or a casual meal with friends, Bella Vista provides the perfect atmosphere.\", metadata={'source': './bella-vista.txt'}),\n",
       " Document(page_content='Q: Do you offer vegetarian or vegan options at Bella Vista?\\nA: Absolutely! Bella Vista boasts a diverse menu that includes a variety of vegetarian and vegan dishes. Our chefs are also happy to customize dishes based on dietary needs.', metadata={'source': './bella-vista.txt'})]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "retriever.get_relevant_documents(query=\"reservation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"bella vista restaurant information search\"\n",
    "    description = \"useful for when you need to answer questions about bella vista restaurant\"\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        store = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        docs = store.get_relevant_documents(query)\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        return \"\\n\".join(text_list)\n",
    "\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "\n",
    "tools = [CustomSearchTool()]\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    verbose=True, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> bella vista restaurant information search: useful for when you need to answer questions about bella vista restaurant\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of bella vista restaurant information search\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "print(agent_chain.agent.llm_chain.prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"bella vista restaurant information search\",\n",
      "    \"action_input\": \"Bella Vista Saturday opening hours\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mQ: What are the hours of operation for Bella Vista?\n",
      "A: Bella Vista is open from 11 a.m. to 11 p.m. from Monday to Saturday. On Sundays, we welcome guests from 12 p.m. to 10 p.m.\n",
      "Q: Do I need a reservation for Bella Vista?\n",
      "A: While walk-ins are always welcome, we recommend making a reservation, especially during weekends and holidays, to ensure a seamless dining experience.\n",
      "Q: Is Bella Vista family-friendly?\n",
      "A: Yes, Bella Vista is a family-friendly establishment. We have a dedicated kids' menu and offer high chairs and booster seats for our younger guests.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Bella Vista is a family-friendly establishment with a dedicated kids' menu and offerings such as high chairs and booster seats for younger guests.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Bella Vista is a family-friendly establishment with a dedicated kids' menu and offerings such as high chairs and booster seats for younger guests.\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"When is Bella Vista open on Saturday?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Bella Vista offers a variety of activities for guests, such as enjoying a meal at the restaurant, taking in the scenic views, and exploring the surrounding area. You can also check out any special events or entertainment that may be happening during your visit.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bella Vista offers a variety of activities for guests, such as enjoying a meal at the restaurant, taking in the scenic views, and exploring the surrounding area. You can also check out any special events or entertainment that may be happening during your visit.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Any suggestions what to do there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
